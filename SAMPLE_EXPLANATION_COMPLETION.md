# ìƒ˜í”Œë³„ XAI ì„¤ëª… ê¸°ëŠ¥ - ì™„ë£Œ ë³´ê³ ì„œ

## âœ… êµ¬í˜„ ì™„ë£Œ

XAI ê¸°ëŠ¥ì´ **ì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„(Global)**ì—ì„œ **ìƒ˜í”Œë³„ ì„¤ëª…(Instance-Level)**ìœ¼ë¡œ í™•ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” ë³€ê²½ì‚¬í•­

### 1. `exp/exp_classification.py` - xai_shap() í•¨ìˆ˜ ì—…ë°ì´íŠ¸

#### ì¶”ê°€ëœ ê¸°ëŠ¥
```python
# ìƒ˜í”Œë³„ ì„¤ëª… ìƒì„± (Instance-level explanation)
for sample_idx in range(len(X_test)):
    pred_class = all_pred_classes[sample_idx]
    pred_prob = all_predictions[sample_idx]
    
    # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ì˜ SHAP values ì¶”ì¶œ
    pred_class_shap = shap_values_list[pred_class][sample_idx]
    
    # ìƒìœ„ íŠ¹ì„± ê³„ì‚°
    top_feature_indices = np.argsort(feature_contributions)[-5:][::-1]
    
    # ìƒ˜í”Œ ì„¤ëª… ê°ì²´ ìƒì„±
    sample_explanation = {
        'sample_idx': int(sample_idx),
        'predicted_class': int(pred_class),
        'predicted_probability': float(pred_prob[pred_class]),
        'true_class': int(true_class),
        'is_correct': int(pred_class) == int(true_class),
        'all_class_probabilities': {...},
        'contrast_class': int(contrast_class),
        'top_contributing_features': [...]
    }
```

#### ìƒˆë¡œìš´ ì¶œë ¥ íŒŒì¼
```
./xai_results/{model_setting}/
â”œâ”€â”€ sample_explanations.json  â† NEW!
â””â”€â”€ ...
```

### 2. `streamlit_app.py` - UI ì—…ë°ì´íŠ¸

#### ìƒˆë¡œìš´ íƒ­ ì¶”ê°€
- ê¸°ì¡´: 4ê°œ íƒ­ (Model Predictions, XAI Analysis, Feature Importance, Alarm & Insights, History)
- í˜„ì¬: **5ê°œ íƒ­** (+ "ğŸ¯ Sample Explanation" ìƒˆë¡œ ì¶”ê°€)

#### ìƒˆë¡œìš´ ê¸°ëŠ¥
- **ìƒ˜í”Œ ë“œë¡­ë‹¤ìš´ ì„ íƒ**: ë¶„ì„í•  ìƒ˜í”Œ ì„ íƒ
- **ê¸°ë³¸ ì •ë³´ ë©”íŠ¸ë¦­**: ì˜ˆì¸¡í´ë˜ìŠ¤, ì‹¤ì œí´ë˜ìŠ¤, ì‹ ë¢°ë„, ëŒ€ì¡°í´ë˜ìŠ¤
- **í™•ë¥  ë¶„í¬ ì°¨íŠ¸**: ëª¨ë“  í´ë˜ìŠ¤ì˜ í™•ë¥  ì‹œê°í™”
- **ìƒìœ„ íŠ¹ì„± ì‹œê°í™”**: ì˜ˆì¸¡ì— ê¸°ì—¬í•œ Top 5 íŠ¹ì„±
- **íŠ¹ì„±ë³„ ê¸°ì—¬ë„ í…Œì´ë¸”**: ìƒì„¸ ìˆ˜ì¹˜
- **ëª¨ë“  íŠ¹ì„± íˆíŠ¸ë§µ**: ì „ì²´ íŠ¹ì„±ì˜ ê¸°ì—¬ë„
- **í•´ì„ ìš”ì•½**: ìë™ ìƒì„±ëœ ì„¤ëª… í…ìŠ¤íŠ¸

## ğŸ“Š ë°ì´í„° êµ¬ì¡°

### sample_explanations.json êµ¬ì¡°
```json
[
  {
    "sample_idx": 0,                           // ìƒ˜í”Œ ë²ˆí˜¸
    "predicted_class": 0,                      // ì˜ˆì¸¡ í´ë˜ìŠ¤
    "predicted_probability": 0.753,            // ì˜ˆì¸¡ í™•ë¥ 
    "true_class": 0,                           // ì‹¤ì œ í´ë˜ìŠ¤
    "is_correct": true,                        // ë§ìŒ/í‹€ë¦¼
    "all_class_probabilities": {               // ëª¨ë“  í´ë˜ìŠ¤ í™•ë¥ 
      "class_0": 0.753,
      "class_1": 0.150,
      "class_2": 0.080,
      "class_3": 0.017
    },
    "contrast_class": 1,                       // 2ìˆœìœ„ í´ë˜ìŠ¤
    "contrast_probability": 0.150,             // 2ìˆœìœ„ í™•ë¥ 
    "top_contributing_features": [
      {
        "feature_idx": 3,
        "contribution_magnitude": 0.1234
      },
      ...
    ],
    "feature_contribution_scores": [...]       // ëª¨ë“  íŠ¹ì„± ê¸°ì—¬ë„
  },
  ...
]
```

## ğŸ” ë¹„êµí‘œ: ì´ì „ vs í˜„ì¬

| í•­ëª© | ì´ì „ (Global) | í˜„ì¬ (Instance-Level) |
|------|---|---|
| **ì„¤ëª… ëŒ€ìƒ** | ëª¨ë“  ìƒ˜í”Œì˜ í‰ê·  | íŠ¹ì • ìƒ˜í”Œ |
| **í´ë˜ìŠ¤ íŠ¹í™”** | ì¼ë°˜ì ì¸ í´ë˜ìŠ¤ íŒ¨í„´ | íŠ¹ì • í´ë˜ìŠ¤ ì˜ˆì¸¡ ì´ìœ  |
| **í™œìš©** | ëª¨ë¸ íŠ¹ì„± ì´í•´ | ê°œë³„ ì˜ˆì¸¡ ë””ë²„ê¹… |
| **ì§ˆë¬¸** | "ì¼ë°˜ì ìœ¼ë¡œ ì–´ë–¤ íŠ¹ì„±ì´ ì¤‘ìš”í•œê°€?" | "ì™œ ì´ ìƒ˜í”Œì´ Class 0ìœ¼ë¡œ ì˜ˆì¸¡ë˜ì—ˆë‚˜?" |
| **ì˜ˆì‹œ** | Class 0ì—ì„œ Feature 3, 5, 7ì´ ì¤‘ìš” | ìƒ˜í”Œ 42ê°€ Class 0ìœ¼ë¡œ ì˜ˆì¸¡ëœ ì´ìœ ëŠ” Feature 3, 5 ë•Œë¬¸ |

## ğŸš€ ì‚¬ìš© íë¦„

### 1ë‹¨ê³„: XAI ë¶„ì„ ì‹¤í–‰
```bash
python run.py --use_xai --xai_num_samples 100
```

**ì¶œë ¥:**
```
Creating SHAP DeepExplainer...
Generating instance-level explanations...
Sample explanations generated for 100 samples
âœ“ sample_explanations.json saved
```

### 2ë‹¨ê³„: Streamlit ì‹¤í–‰
```bash
streamlit run streamlit_app.py
```

### 3ë‹¨ê³„: "ğŸ¯ Sample Explanation" íƒ­ ì„ íƒ

### 4ë‹¨ê³„: ìƒ˜í”Œ ì„ íƒ ë° ë¶„ì„
- ë“œë¡­ë‹¤ìš´ì—ì„œ ìƒ˜í”Œ ì„ íƒ
- ìë™ ìƒì„±ë˜ëŠ” ì„¤ëª… í™•ì¸
- íŠ¹ì„± ê¸°ì—¬ë„ ì‹œê°í™” í™•ì¸

## ğŸ’» ì½”ë“œ ì˜ˆì‹œ

### sample_explanations í™œìš© (Python)
```python
import json

with open('./xai_results/{model}/sample_explanations.json') as f:
    explanations = json.load(f)

# ìƒ˜í”Œ 0ì˜ ì„¤ëª… ë³´ê¸°
exp = explanations[0]
print(f"Sample 0 was predicted as Class {exp['predicted_class']}")
print(f"Confidence: {exp['predicted_probability']:.2%}")
print(f"True class: {exp['true_class']}")

# ìƒìœ„ íŠ¹ì„± í™•ì¸
for feat in exp['top_contributing_features'][:3]:
    print(f"  Feature {feat['feature_idx']}: {feat['contribution_magnitude']:.4f}")
```

### ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ì°¾ê¸°
```python
# í‹€ë¦° ìƒ˜í”Œë§Œ í•„í„°ë§
wrong_predictions = [e for e in explanations if not e['is_correct']]

# ê° ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ë¶„ì„
for exp in wrong_predictions[:5]:
    print(f"Sample {exp['sample_idx']}: "
          f"Predicted {exp['predicted_class']}, "
          f"Actually {exp['true_class']}")
```

## ğŸ“ˆ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: íŠ¹ì • ì˜¤ë¥˜ ë¶„ì„
```
ì˜¤ë¶„ë¥˜ ìƒ˜í”Œì„ ì„ íƒí•˜ë©´:
- ëª¨ë¸ì´ ì™œ í‹€ë ¸ëŠ”ì§€ ëª…í™•í•˜ê²Œ í™•ì¸
- ì–´ë–¤ íŠ¹ì„±ì´ ì˜¤ë„í–ˆëŠ”ì§€ íŒŒì•…
- íŠ¹ì„± ì „ì²˜ë¦¬ ë°©ë²• ê°œì„  ê°€ëŠ¥
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ëª¨ë¸ ì‹ ë¢°ì„± í‰ê°€
```
ì—¬ëŸ¬ ìƒ˜í”Œì„ ë¹„êµí•˜ë©´:
- ì–´ë–¤ í´ë˜ìŠ¤ê°€ ì‰½ê²Œ êµ¬ë¶„ë˜ëŠ”ì§€ í™•ì¸
- ì–´ë–¤ í´ë˜ìŠ¤ê°€ í˜¼ë™ë˜ëŠ”ì§€ ë°œê²¬
- ëª¨ë¸ì˜ ê°•ì /ì•½ì  íŒŒì•…
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: íŠ¹ì„± ê²€ì¦
```
ë„ë©”ì¸ ì „ë¬¸ê°€ê°€ í™•ì¸í•˜ë©´:
- ëª¨ë¸ì˜ ì˜ì‚¬ê²°ì •ì´ íƒ€ë‹¹í•œì§€ ê²€ì¦
- í†µê³„ì  ì´ìƒ ë°œê²¬
- ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ ê°ì§€
```

## âœ¨ ì£¼ìš” ê°œì„ ì‚¬í•­

| # | ê°œì„ ì‚¬í•­ | íš¨ê³¼ |
|---|---------|------|
| 1 | Instance-level SHAP | ê°œë³„ ì˜ˆì¸¡ ì„¤ëª… ê°€ëŠ¥ |
| 2 | ìƒ˜í”Œë³„ ë©”íŠ¸ë¦­ | ì‹ ë¢°ë„ í™•ì¸ ê°€ëŠ¥ |
| 3 | í™•ë¥  ë¶„í¬ ì‹œê°í™” | í´ë˜ìŠ¤ ê°„ ì°¨ì´ ëª…í™• |
| 4 | ìƒìœ„ íŠ¹ì„± ê°•ì¡° | ì£¼ìš” íŠ¹ì„± ì‰½ê²Œ íŒŒì•… |
| 5 | ëª¨ë“  íŠ¹ì„± íˆíŠ¸ë§µ | ì „ì²´ ê·¸ë¦¼ í•œëˆˆì— |
| 6 | í•´ì„ ìš”ì•½ | ìë™ ìƒì„±ëœ ì„¤ëª… |
| 7 | JSON ì €ì¥ | í”„ë¡œê·¸ë˜ë° í™œìš© ê°€ëŠ¥ |

## ğŸ”§ í™•ì¸ ì‚¬í•­

### ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
```bash
python verify_sample_explanations.py
```

**ì¶œë ¥:**
```
âœ“ sample_explanations.json found
âœ“ JSON loaded successfully
  Total samples: 100

ğŸ“‹ First Sample Explanation Structure:
  - sample_idx: 0
  - predicted_class: 0
  - predicted_probability: 75.30%
  ...

âœ… All checks passed!
```

### ë¬¸ë²• í™•ì¸
```bash
python -m py_compile exp/exp_classification.py streamlit_app.py
```

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

1. **SAMPLE_EXPLANATION_GUIDE.md** - ìƒì„¸ ì‚¬ìš© ê°€ì´ë“œ
2. **verify_sample_explanations.py** - ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
3. **exp/exp_classification.py** - êµ¬í˜„ ì½”ë“œ

## ğŸ“ ê¸°ìˆ  ì„¤ëª…

### Instance-Level SHAPì˜ ì˜ë¯¸

**SHAP values**ëŠ” ê° íŠ¹ì„±ì´ ì˜ˆì¸¡ê°’ì„ ê²°ì •í•˜ëŠ” ë° ê¸°ì—¬í•˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •:

```
Base value (ë¬´ì‘ìœ„ ì˜ˆì¸¡): 50%

Feature 3 contribution: +15%
Feature 5 contribution: +8%
Feature 0 contribution: +2%

Final prediction: 50% + 15% + 8% + 2% = 75% â†’ Class 0
```

**Instance-level**ì€ ì´ë¥¼ **íŠ¹ì • ìƒ˜í”Œ**ì— ëŒ€í•´ ê³„ì‚°:
- ê° ìƒ˜í”Œë§ˆë‹¤ ë‹¤ë¥¸ ê¸°ì—¬ë„
- ê°™ì€ íŠ¹ì„±ë„ ìƒ˜í”Œì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì‘ìš©
- ê°œë³„ ì˜ˆì¸¡ì˜ ì´ìœ ë¥¼ ì •í™•í•˜ê²Œ ì„¤ëª…

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. âœ… XAI ë¶„ì„ ì¬ì‹¤í–‰
   ```bash
   python run.py --use_xai --xai_num_samples 100
   ```

2. âœ… ê²°ê³¼ í™•ì¸
   ```bash
   python verify_sample_explanations.py
   ```

3. âœ… Streamlit ì‹¤í–‰
   ```bash
   streamlit run streamlit_app.py
   ```

4. âœ… "ğŸ¯ Sample Explanation" íƒ­ì—ì„œ ìƒ˜í”Œ ë¶„ì„

5. â­ï¸ ì˜¤ë¥˜ ë¶„ì„ ë° ëª¨ë¸ ê°œì„ 

---

**ìƒíƒœ**: âœ… ì™„ë£Œ ë° ê²€ì¦ë¨  
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2026-02-18  
**ë²„ì „**: 2.0
