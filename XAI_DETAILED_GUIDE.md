# XAI ì—ëŸ¬ ìˆ˜ì • ìƒì„¸ ê°€ì´ë“œ

## ğŸ› ë°œìƒí–ˆë˜ ì—ëŸ¬

```
RuntimeError: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 3
File "/home/sung145/miniconda3/lib/python3.13/site-packages/shap/explainers/_deep/deep_pytorch.py", line 372, in nonlinear_1d
```

## ğŸ” ì—ëŸ¬ì˜ ì›ì¸ ë¶„ì„

### 1. **DeepExplainerì˜ í•œê³„**
- SHAPì˜ `DeepExplainer`ëŠ” ëª¨ë¸ì˜ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ì¶”ì í•´ì•¼ í•¨
- TimesNet ëª¨ë¸ì˜ ë³µì¡í•œ FFT ì—°ì‚°ê³¼ ë™ì  paddingìœ¼ë¡œ ì¸í•´ í˜•íƒœ ë³€í™˜ì´ ì¼ì–´ë‚¨
- ë°°ê²½ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì°¨ì›ì´ í˜¸í™˜ë˜ì§€ ì•ŠìŒ

### 2. **ì…ë ¥ ë°ì´í„° ì°¨ì› ë¶ˆì¼ì¹˜**
```
ë°°ê²½ ë°ì´í„°: (N_bg, seq_len, n_features) = (100, 16, 7)
í…ŒìŠ¤íŠ¸ ë°ì´í„°: (N_test, seq_len, n_features) = (100, 16, 7)

â†“ FFTì™€ padding ê³¼ì •ì—ì„œ

ì‹¤ì œ ì²˜ë¦¬: (batch_size, 5) vs (batch_size, 4) â† ì°¨ì› ë¶ˆì¼ì¹˜!
```

### 3. **ëª¨ë¸ì˜ ë™ì  í˜•íƒœ ë³€í™˜**
```python
# TimesNetì˜ forward pass
def forward(self, x):
    # x shape: (batch, seq_len, features)
    enc_out = self.enc_embedding(x, None)
    
    for i in range(self.layer):
        enc_out = self.layer_norm(self.model[i](enc_out))
        # TimesBlock ë‚´ë¶€ì—ì„œ FFT + padding + reshape
        # â†’ ì°¨ì›ì´ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•˜ê²Œ ë³€í•¨
    
    output = output.reshape(output.shape[0], -1)
    output = self.projection(output)  # (batch, num_classes)
    return output
```

## âœ… ì ìš©ëœ í•´ê²°ì±…

### 1ï¸âƒ£ **Explainer ë³€ê²½: DeepExplainer â†’ KernelExplainer**

#### ë³€ê²½ ì „ (ë¬¸ì œ ë°œìƒ)
```python
explainer = shap.DeepExplainer(self.model, background_tensor)
shap_values = explainer.shap_values(X_test_tensor)  # âŒ ì—ëŸ¬!
```

#### ë³€ê²½ í›„ (ì•ˆì •ì )
```python
# KernelExplainer: ëª¨ë¸ ë…ë¦½ì ì¸ ë¸”ë™ë°•ìŠ¤ ë°©ì‹
explainer = shap.KernelExplainer(
    predict_flat,  # ë˜í•‘ëœ ì˜ˆì¸¡ í•¨ìˆ˜
    background_subsample,  # ë°°ê²½ ë°ì´í„°
    link="logit"
)
shap_values = explainer.shap_values(test_subsample)  # âœ“ ì‘ë™!
```

### 2ï¸âƒ£ **ë°ì´í„° í‰íƒ„í™” (Flattening)**

#### ë³€ê²½ ì „
```python
# 3D ë°°ì—´ ì§ì ‘ ì „ë‹¬
background_data.shape = (100, 16, 7)  # âŒ ì°¨ì› ë¶ˆì¼ì¹˜ ë¬¸ì œ
X_test.shape = (100, 16, 7)
```

#### ë³€ê²½ í›„
```python
# 1Dë¡œ í‰íƒ„í™” â†’ ì˜ˆì¸¡ í•¨ìˆ˜ì—ì„œ ë³µì›
background_data_flat = background_data.reshape(background_data.shape[0], -1)
# (100, 112) = (100, 16*7)

X_test_flat = X_test.reshape(X_test.shape[0], -1)
# (100, 112) = (100, 16*7)

# SHAPì€ í‰íƒ„í™”ëœ ë°ì´í„°ë¡œ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™
```

### 3ï¸âƒ£ **ë˜í¼ í•¨ìˆ˜ë¡œ ìë™ ì°¨ì› ë³€í™˜**

```python
def predict_flat(x):
    """
    ì…ë ¥: (batch_size, flattened_features)
    ì¶œë ¥: (batch_size, num_classes)
    """
    # ìë™ìœ¼ë¡œ 3Dë¡œ ë³µì›
    batch_size = x.shape[0]
    x_reshaped = x.reshape(batch_size, 16, 7)  # ì›ë˜ shapeìœ¼ë¡œ ë³µì›
    
    # ëª¨ë¸ì— ì „ë‹¬
    return model_predict_wrapper(x_reshaped)
```

### 4ï¸âƒ£ **ì—ëŸ¬ ì²˜ë¦¬ ë° í´ë°±**

```python
try:
    # KernelExplainer ì‹œë„
    explainer = shap.KernelExplainer(predict_flat, background_subsample)
    shap_values = explainer.shap_values(test_subsample)
    print("âœ“ SHAP values computed successfully")
    
except Exception as e:
    # ì‹¤íŒ¨ ì‹œ ê·¸ë˜ë””ì–¸íŠ¸ ê¸°ë°˜ ë°©ë²•ìœ¼ë¡œ í´ë°±
    print(f"Warning: SHAP computation failed: {e}")
    print("Using alternative approach: Computing feature importance from gradients...")
    
    # ê·¸ë˜ë””ì–¸íŠ¸ ê¸°ë°˜ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
    # (ë” ë¹ ë¥´ì§€ë§Œ ëœ ì •í™•í•¨)
```

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

| í•­ëª© | ë³€ê²½ ì „ | ë³€ê²½ í›„ |
|------|--------|--------|
| **Explainer** | DeepExplainer | KernelExplainer |
| **ì•ˆì •ì„±** | âŒ ì—ëŸ¬ ë°œìƒ | âœ… ì•ˆì •ì  |
| **í˜¸í™˜ì„±** | ëª¨ë¸ ì˜ì¡´ì  | ëª¨ë¸ ë…ë¦½ì  |
| **ê³„ì‚° ì†ë„** | ë¹ ë¦„ | ì¤‘ê°„ |
| **ì •í™•ë„** | ë†’ìŒ | ì¶©ë¶„í•¨ |
| **í´ë°± ì§€ì›** | âŒ ì—†ìŒ | âœ… ìˆìŒ |

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. XAI ë¶„ì„ì„ í¬í•¨í•˜ì—¬ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸

```bash
# ê¸°ë³¸ ì„¤ì •
python run.py --use_xai

# ìƒ˜í”Œ ìˆ˜ ì§€ì •
python run.py --use_xai --xai_num_samples 100

# ì „ì²´ ì˜µì…˜ ì˜ˆì‹œ
python run.py \
  --model TimesNet \
  --data OHT_fire \
  --is_training 1 \
  --train_epochs 10 \
  --use_xai \
  --xai_num_samples 100
```

### 2. ê²°ê³¼ í™•ì¸

ê²°ê³¼ëŠ” `./xai_results/{setting}/` í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤:

```
xai_results/
â””â”€â”€ TSC_dm64_dff128_topk3_sl16_nminmax/
    â”œâ”€â”€ xai_analysis.json           # âœ“ ìƒì„¸ ë¶„ì„ ë°ì´í„°
    â”œâ”€â”€ xai_summary.txt             # âœ“ í…ìŠ¤íŠ¸ ìš”ì•½ ë³´ê³ ì„œ
    â”œâ”€â”€ feature_importance.png      # âœ“ ì‹œê°í™” (í´ë˜ìŠ¤ë³„)
    â”œâ”€â”€ X_test.npy                  # í…ŒìŠ¤íŠ¸ ì…ë ¥
    â”œâ”€â”€ y_test.npy                  # í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”
    â”œâ”€â”€ shap_values_class_0.npy     # SHAP values (Class 0)
    â”œâ”€â”€ shap_values_class_1.npy     # SHAP values (Class 1)
    â”œâ”€â”€ shap_values_class_2.npy     # SHAP values (Class 2)
    â””â”€â”€ shap_values_class_3.npy     # SHAP values (Class 3)
```

### 3. Streamlit ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸

```bash
streamlit run streamlit_app.py
```

ëŒ€ì‹œë³´ë“œì˜ **"ğŸ” XAI Analysis"** íƒ­ì—ì„œ:
- ëª¨ë¸ ì •í™•ë„
- ê° í´ë˜ìŠ¤ë³„ íŠ¹ì„± ì¤‘ìš”ë„
- ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„± (ì‹œê°í™” + ìˆ˜ì¹˜)
- SHAP í†µê³„

## ğŸ“ˆ ì¶œë ¥ ì˜ˆì‹œ

### xai_summary.txt
```
SHAP XAI Analysis Summary
========================
Model: TSC_dm64_dff128_topk3_sl16_nminmax
Total Samples Analyzed: 100
Number of Classes: 4
Model Accuracy on Test Set: 0.8500

Input Shape: (100, 16, 7)
Flattened Feature Dimension: (100, 112)

Feature Importance (Mean |SHAP value|):

  Class 0:
    Feature 42: 0.234567
    Feature 53: 0.198765
    Feature 28: 0.176543
    ...
```

### xai_analysis.json
```json
{
  "total_samples": 100,
  "num_classes": 4,
  "model_accuracy": 0.85,
  "feature_importance": {
    "class_0": [0.234, 0.198, 0.176, ...],
    "class_1": [0.156, 0.143, 0.132, ...],
    ...
  },
  "predictions": [0, 1, 2, ...],
  "true_labels": [0, 1, 2, ...],
  "prediction_probabilities": [[0.9, 0.05, ...], ...]
}
```

## ğŸ”§ ê³ ê¸‰ ì˜µì…˜

### ê³„ì‚°ëŸ‰ ì¡°ì ˆ

í° ë°ì´í„°ì…‹ì˜ ê²½ìš° ìƒ˜í”Œ ìˆ˜ë¥¼ ì¤„ì´ì„¸ìš”:

```bash
# ë¹ ë¥¸ ë¶„ì„ (ì‘ì€ ìƒ˜í”Œ)
python run.py --use_xai --xai_num_samples 20

# ì •ë°€í•œ ë¶„ì„ (í° ìƒ˜í”Œ)
python run.py --use_xai --xai_num_samples 200
```

### ë©”ëª¨ë¦¬ ìµœì í™”

`exp_classification.py`ì—ì„œ ë‹¤ìŒ ê°’ì„ ì¡°ì •:

```python
# ì•½ 50ì¤„ ê·¼ì²˜
background_subsample = shap.sample(background_data_flat, min(50, ...))  # â† ì´ ê°’ ì¡°ì •
test_subsample = X_test_flat[:min(20, X_test_flat.shape[0])]  # â† ì´ ê°’ ì¡°ì •
```

## âœ¨ ì£¼ìš” ê°œì„  ì‚¬í•­ ìš”ì•½

| # | ê°œì„  ì‚¬í•­ | íš¨ê³¼ |
|---|---------|------|
| 1 | KernelExplainer ì‚¬ìš© | âœ“ ì—ëŸ¬ í•´ê²° |
| 2 | ë°ì´í„° í‰íƒ„í™” | âœ“ ì°¨ì› í˜¸í™˜ì„± |
| 3 | ì˜ˆì¸¡ ë˜í¼ í•¨ìˆ˜ | âœ“ ìë™ ì°¨ì› ë³€í™˜ |
| 4 | ì—ëŸ¬ ì²˜ë¦¬ | âœ“ ì•ˆì •ì„± í–¥ìƒ |
| 5 | ê³„ì‚° ìµœì í™” | âœ“ ì„±ëŠ¥ í–¥ìƒ |
| 6 | ê²°ê³¼ ì‹œê°í™” | âœ“ í•´ì„ì„± í–¥ìƒ |

## ğŸ“ ë¬¸ì œ í•´ê²°

### Q: XAI ë¶„ì„ì´ ë„ˆë¬´ ëŠë¦½ë‹ˆë‹¤
**A:** `--xai_num_samples` ê°’ì„ ì¤„ì—¬ë³´ì„¸ìš”
```bash
python run.py --use_xai --xai_num_samples 50
```

### Q: ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤
**A:** `exp_classification.py`ì—ì„œ ì„œë¸Œìƒ˜í”Œë§ ê°’ ì¡°ì •:
```python
# ì¤„ ì•½ 350 ê·¼ì²˜
background_subsample = shap.sample(background_data_flat, min(20, ...))
test_subsample = X_test_flat[:min(10, X_test_flat.shape[0])]
```

### Q: Streamlitì—ì„œ XAI ê²°ê³¼ê°€ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤
**A:** ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:
1. XAI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ê°€ (`--use_xai` í”Œë˜ê·¸ ì‚¬ìš©)
2. `./xai_results/{model_setting}/` í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ê°€
3. JSON íŒŒì¼ì´ ìƒì„±ë˜ì—ˆëŠ”ê°€

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. âœ… ìˆ˜ì •ëœ ì½”ë“œë¡œ XAI ë¶„ì„ ì‹¤í–‰
2. âœ… ê²°ê³¼ í™•ì¸ ë° ê²€ì¦
3. âœ… Streamlit ëŒ€ì‹œë³´ë“œì—ì„œ ì‹œê°í™” í™•ì¸
4. â­ï¸ í”„ë¡œë•ì…˜ ë°°í¬

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2026-02-18  
**ë²„ì „**: 1.0  
**ìƒíƒœ**: âœ… ì™„ë£Œ ë° ê²€ì¦ë¨
